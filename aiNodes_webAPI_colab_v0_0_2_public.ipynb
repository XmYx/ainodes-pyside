{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XmYx/ainodes-pyside/blob/main/aiNodes_webAPI_colab_v0_0_2_public.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxIgJkzxnx5s",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown **NVIDIA GPU**\n",
        "import subprocess, os, sys\n",
        "sub_p_res = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.free', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "print(f\"{sub_p_res[:-1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yIqFa0kn9VL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import subprocess, time, gc, os, sys\n",
        "\n",
        "def setup_environment():\n",
        "    print_subprocess = False\n",
        "    use_xformers_for_colab = True\n",
        "    try:\n",
        "        ipy = get_ipython()\n",
        "    except:\n",
        "        ipy = 'could not get_ipython'\n",
        "    if 'google.colab' in str(ipy):\n",
        "        print(\"..setting up environment\")\n",
        "        start_time = time.time()\n",
        "        all_process = [\n",
        "            ['pip', 'install', 'torch==1.12.1+cu113', 'torchvision==0.13.1+cu113', '--extra-index-url', 'https://download.pytorch.org/whl/cu113'],\n",
        "            ['pip', 'install', 'omegaconf==2.2.3', 'einops==0.4.1', 'pytorch-lightning==1.7.4', 'torchmetrics==0.9.3', 'torchtext==0.13.1', 'transformers==4.21.2', 'kornia==0.6.7'],\n",
        "            ['git', 'clone', 'https://github.com/deforum-art/deforum-stable-diffusion'],\n",
        "            ['pip', 'install', 'accelerate', 'ftfy', 'jsonmerge', 'matplotlib', 'resize-right', 'timm', 'torchdiffeq','scikit-learn'],\n",
        "            ['pip', 'install', 'fastapi', 'uvicorn', 'pydantic'],\n",
        "            ['git', 'clone', 'https://github.com/XmYx/ainodes-pyside'],\n",
        "        ]\n",
        "        for process in all_process:\n",
        "            running = subprocess.run(process,stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            if print_subprocess:\n",
        "                print(running)\n",
        "        with open('deforum-stable-diffusion/src/k_diffusion/__init__.py', 'w') as f:\n",
        "            f.write('')\n",
        "        sys.path.extend([\n",
        "            'deforum-stable-diffusion/',\n",
        "            'deforum-stable-diffusion/src',\n",
        "        ])\n",
        "        end_time = time.time()\n",
        "\n",
        "        if use_xformers_for_colab:\n",
        "\n",
        "            print(\"..installing xformers\")\n",
        "\n",
        "            all_process = [['pip', 'install', 'triton==2.0.0.dev20220701']]\n",
        "            for process in all_process:\n",
        "                running = subprocess.run(process,stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "                if print_subprocess:\n",
        "                    print(running)\n",
        "                    \n",
        "            v_card_name = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            if 't4' in v_card_name.lower():\n",
        "                name_to_download = 'T4'\n",
        "            elif 'v100' in v_card_name.lower():\n",
        "                name_to_download = 'V100'\n",
        "            elif 'a100' in v_card_name.lower():\n",
        "                name_to_download = 'A100'\n",
        "            elif 'p100' in v_card_name.lower():\n",
        "                name_to_download = 'P100'\n",
        "            else:\n",
        "                print(v_card_name + ' is currently not supported with xformers flash attention in deforum!')\n",
        "\n",
        "            x_ver = 'xformers-0.0.13.dev0-py3-none-any.whl'\n",
        "            x_link = 'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/' + name_to_download + '/' + x_ver\n",
        "        \n",
        "            all_process = [\n",
        "                ['wget', x_link],\n",
        "                ['pip', 'install', x_ver],\n",
        "                ['mv', 'deforum-stable-diffusion/src/ldm/modules/attention.py', 'deforum-stable-diffusion/src/ldm/modules/attention_backup.py'],\n",
        "                ['mv', 'deforum-stable-diffusion/src/ldm/modules/attention_xformers.py', 'deforum-stable-diffusion/src/ldm/modules/attention.py']\n",
        "            ]\n",
        "\n",
        "            for process in all_process:\n",
        "                running = subprocess.run(process,stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "                if print_subprocess:\n",
        "                    print(running)\n",
        "\n",
        "            print(f\"Environment set up in {end_time-start_time:.0f} seconds\")\n",
        "    else:\n",
        "        sys.path.extend([\n",
        "            'src'\n",
        "        ])\n",
        "    return\n",
        "\n",
        "setup_environment()\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import clip\n",
        "#from IPython import display\n",
        "#from types import SimpleNamespace\n",
        "#from helpers.save_images import get_output_folder\n",
        "#from helpers.settings import load_args\n",
        "#from helpers.render import render_animation, render_input_video, render_image_batch, render_interpolation\n",
        "#from helpers.model_load import make_linear_decode, load_model, get_model_output_paths\n",
        "#from helpers.aesthetics import load_aesthetics_model\n",
        "\n",
        "#@markdown **Setup and Start**\n",
        "\n",
        "#def Root():\n",
        "#    models_path = \"models\" #@param {type:\"string\"}\n",
        "#    configs_path = \"configs\" #@param {type:\"string\"}\n",
        "#    output_path = \"output\" #@param {type:\"string\"}\n",
        "#    mount_google_drive = True #@param {type:\"boolean\"}\n",
        "#    models_path_gdrive = \"/content/drive/MyDrive/AI/models\" #@param {type:\"string\"}\n",
        "#    output_path_gdrive = \"/content/drive/MyDrive/AI/StableDiffusion\" #@param {type:\"string\"}\n",
        "#\n",
        "#    #@markdown **Model Setup**\n",
        "#    model_config = \"v1-inference.yaml\" #@param [\"custom\",\"v1-inference.yaml\"]\n",
        "#    model_checkpoint =  \"v1-5-pruned-emaonly.ckpt\" #@param [\"custom\",\"v1-5-pruned.ckpt\",\"v1-5-pruned-emaonly.ckpt\",\"sd-v1-4-full-ema.ckpt\",\"sd-v1-4.ckpt\",\"sd-v1-3-full-ema.ckpt\",\"sd-v1-3.ckpt\",\"sd-v1-2-full-ema.ckpt\",\"sd-v1-2.ckpt\",\"sd-v1-1-full-ema.ckpt\",\"sd-v1-1.ckpt\", \"robo-diffusion-v1.ckpt\",\"wd-v1-3-float16.ckpt\"]\n",
        "#    custom_config_path = \"\" #@param {type:\"string\"}\n",
        "#    custom_checkpoint_path = \"\" #@param {type:\"string\"}\n",
        "#    half_precision = True\n",
        "#    return locals()\n",
        "\n",
        "#root = Root()\n",
        "#root = SimpleNamespace(**root)\n",
        "\n",
        "#root.models_path, root.output_path = get_model_output_paths(root)\n",
        "#root.model, root.device = load_model(root, \n",
        "#                                    load_on_run_all=True\n",
        "#                                    , \n",
        "#                                    check_sha256=True\n",
        "#                                    )\n",
        "\n",
        "#!pip install -e git+https://github.com/osi1880vr/pytorch3d-lite.git\n",
        "!pip install fonts\n",
        "!pip install font-roboto piexif lark\n",
        "!pip install nest_asyncio\n",
        "!pip install pyngrok\n",
        "\n",
        "!pip install k-diffusion\n",
        "!pip install -qq https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.14/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "%cd /content/ainodes-pyside\n",
        "!python install.py\n",
        "!pip install -e .\n",
        "!git clone https://github.com/osi1880vr/AdaBins.git\n",
        "!git clone https://github.com/osi1880vr/MiDaS.git\n",
        "!git clone https://github.com/osi1880vr/pytorch3d-lite.git\n",
        "!pip install -e pytorch3d-lite\n",
        "!pip install -e MiDaS\n",
        "!pip install -e AdaBins\n",
        "%cd /content/ainodes-pyside\n",
        "!git pull\n",
        "!python apis/fast_app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Start Again"
      ],
      "metadata": {
        "id": "lJVEub3KsBbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGcOi5UcqOeZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown **Start Again**\n",
        "\n",
        "%cd /content/ainodes-pyside\n",
        "!git checkout main\n",
        "!git pull\n",
        "!python apis/fast_app.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM93A2u/eF8vVf1HcpKzo1R",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}